# -*- coding: utf-8 -*-
"""Week15_LiveCoding_Tasks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_jjMhHBakrIejR1iwCM7hDZJqcextHC7

**TASK-15A:** Please provide a basic model with Gaussian Naive Bayes for species prediction.

- X: 4 features (150 cases)
- y: species (3 different, 150 cases)
- train-test split: X_train, X_test, 
- "fit" the model with the train dataset (without crossvalidation step)
- then run the model with the test dataset (predict)
- provide the accuracy of this model as an output
- please use predict_proba function to generate the probability values for the test dataset
"""

from sklearn.datasets import load_iris
# sklearn.datasets includes common example datasets

# A function to load in the iris dataset
iris_obj = load_iris()

# Dataset preview
print("data:", iris_obj.data)     # Names of the columns
print(iris_obj.feature_names)     # Names of the features/variables
print(iris_obj.target)            # Target values
print(iris_obj.target_names)      # name of target variable

X = iris_obj.data
y = iris_obj.target

from sklearn.naive_bayes import GaussianNB
model = GaussianNB()
model.fit(X, y);

# train-test split: X_train, X_test,
from sklearn.model_selection import train_test_split
X1,X2,y1,y2 = train_test_split(X,y,random_state=0, train_size=0.5)

from sklearn.metrics import accuracy_score
model.fit(X1,y1) # "fit" the model with the train dataset (without crossvalidation step)
y2_model = model.predict(X2) # then run the model with the test dataset (predict)
accuracy_score(y2,y2_model) # provide the accuracy of this model as an output

model.predict_proba(X2) # please use predict_proba function to generate the probability values for the test dataset

"""**TASK-15B:** Please run it with 3-fold and 5-fold crossvalidation on the whole dataset 
and display the results (accuracy).

"""

# Model Validation for k=3 and k=5 
from sklearn.model_selection import cross_val_score
print(cross_val_score(model,X,y,cv=3))
print(cross_val_score(model,X,y,cv=5))

"""**TASK-15C:** Please run the gridsearchCV function on the train dataset with 3 different algorithms.

- One of them is Gaussian Naive Bayes - you should find the unknown parameter and use it in the hyperparameter
fine tuning process.

- The other one will be kNN and please also apply hyperparameter fine tuning with the use of gridsearchCV.

- The next one is up to you. You will decide on the algorithm (this can be decision tree algorithm).
  You can use the following parameters: criterion, max_depth.


"""

from sklearn.model_selection import GridSearchCV

from sklearn.naive_bayes import GaussianNB # Gaussian Naive Bayes 
model = GaussianNB()

param_grid1 = {'var_smoothing': [10e-8,10e-9,10e-10]}

grid = GridSearchCV(model, param_grid1, cv=5)
grid.fit(X1, y1) # Apply model with between X1 and y. I choose petal_width vfeatures for visualizations
grid.best_params_

from sklearn.neighbors import KNeighborsClassifier # kNN
model = KNeighborsClassifier()

param_grid2 = {'n_neighbors': [3,5,7]}

grid = GridSearchCV(model, param_grid2, cv=5)
grid.fit(X1, y1) # Apply model with between X1 and y. I choose petal_width vfeatures for visualizations
grid.best_params_

from sklearn.tree import DecisionTreeClassifier # decision tree algorithm
model = DecisionTreeClassifier()

param_grid3 = {'criterion': ["gini","entropy"],"splitter":["best", "random"],"max_depth":[1,3,5,7]}

grid = GridSearchCV(model, param_grid3, cv=5)
grid.fit(X1, y1) # Apply model with between X1 and y. I choose petal_width vfeatures for visualizations
grid.best_params_